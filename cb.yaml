# CodeBuild buildspec for CI builds - builds Rails apps with multiple strategies
# BUILD_STRATEGY: nix-bundler (default), nix-bundix, dockerfile
version: 0.2

env:
  shell: bash

phases:
  install:
    commands:
      - |
        echo "|--------------------  INSTALL -----------------------|"
        mkdir -p ~/.ssh && chmod 700 ~/.ssh
        aws ssm get-parameter --name "/applications/${APP_NAME}/app_deploy_key" --with-decryption --query 'Parameter.Value' --output text > ~/.ssh/app_deploy_key 2>/dev/null || true
        [ -s ~/.ssh/app_deploy_key ] && chmod 600 ~/.ssh/app_deploy_key || rm -f ~/.ssh/app_deploy_key
        aws ssm get-parameter --name "/applications/${APP_NAME}/config_deploy_key" --with-decryption --query 'Parameter.Value' --output text > ~/.ssh/config_deploy_key 2>/dev/null || true
        [ -s ~/.ssh/config_deploy_key ] && chmod 600 ~/.ssh/config_deploy_key || rm -f ~/.ssh/config_deploy_key
      - |
        APP_HOST=$(echo "${GIT_REPO_URL}" | sed -n 's/.*@\([^:]*\):.*/\1/p')
        CONFIG_HOST=$(echo "${MACHINE_CONFIGS_REPO}" | sed -n 's|.*://git@\([^/]*\)/.*|\1|p')
        cat > ~/.ssh/config << EOF
        Host app-repo
          HostName ${APP_HOST:-github.com}
          User git
          IdentityFile ~/.ssh/app_deploy_key
          StrictHostKeyChecking no
        Host config-repo
          HostName ${CONFIG_HOST:-github.com}
          User git
          IdentityFile ~/.ssh/config_deploy_key
          StrictHostKeyChecking no
        Host github.com gitlab.com bitbucket.org
          User git
          IdentityFile ~/.ssh/app_deploy_key
          StrictHostKeyChecking no
        Host *
          StrictHostKeyChecking no
        EOF
        chmod 600 ~/.ssh/config
      - |
        echo "${GIT_REPO_URL}" | sed 's/@[^:]*:/@app-repo:/' > /tmp/app_repo_url
        echo "${MACHINE_CONFIGS_REPO}" | sed 's|://git@[^/]*/|://git@config-repo/|' > /tmp/config_repo_url
      - |
        GITHUB_TOKEN=$(aws ssm get-parameter --name "/applications/${APP_NAME}/github_token" --with-decryption --query 'Parameter.Value' --output text 2>/dev/null || true)
        if [ -n "$GITHUB_TOKEN" ]; then
          echo "$GITHUB_TOKEN" > /tmp/.github_token && chmod 600 /tmp/.github_token
          git config --global url."https://${GITHUB_TOKEN}@github.com/".insteadOf "https://github.com/"
        fi
      - |
        NIX_SIGNING_KEY=$(aws ssm get-parameter --name "/applications/${APP_NAME}/nix_cache_signing_key" --with-decryption --query 'Parameter.Value' --output text 2>/dev/null || true)
        [ -n "$NIX_SIGNING_KEY" ] && echo "$NIX_SIGNING_KEY" > /tmp/.nix_signing_key && chmod 600 /tmp/.nix_signing_key
        NIX_CACHE_PUBLIC_KEY=$(aws ssm get-parameter --name "/applications/${APP_NAME}/nix_cache_public_key" --query 'Parameter.Value' --output text 2>/dev/null || true)
        [ -n "$NIX_CACHE_PUBLIC_KEY" ] && echo "$NIX_CACHE_PUBLIC_KEY" > /tmp/.nix_public_key
      - 'curl -L https://nixos.org/nix/install | sh -s -- --daemon'
      - . /nix/var/nix/profiles/default/etc/profile.d/nix-daemon.sh
      - |
        # Configure AWS credentials for Nix S3 binary cache access
        # CodeBuild uses container credentials (via HTTP endpoint), but we can also
        # get temporary credentials from the metadata service for the nix-daemon.
        # First, fetch credentials from the CodeBuild credential provider
        if [ -n "${AWS_CONTAINER_CREDENTIALS_RELATIVE_URI:-}" ]; then
          echo "Fetching AWS credentials from container credential provider..."
          CREDS=$(curl -s "http://169.254.170.2${AWS_CONTAINER_CREDENTIALS_RELATIVE_URI}")
          export AWS_ACCESS_KEY_ID=$(echo "$CREDS" | jq -r '.AccessKeyId')
          export AWS_SECRET_ACCESS_KEY=$(echo "$CREDS" | jq -r '.SecretAccessKey')
          export AWS_SESSION_TOKEN=$(echo "$CREDS" | jq -r '.Token')
        fi
        # Create credentials and config files for the nix-daemon (runs as root)
        mkdir -p /root/.aws
        cat > /root/.aws/credentials << AWSEOF
        [default]
        aws_access_key_id = ${AWS_ACCESS_KEY_ID}
        aws_secret_access_key = ${AWS_SECRET_ACCESS_KEY}
        aws_session_token = ${AWS_SESSION_TOKEN}
        AWSEOF
        chmod 600 /root/.aws/credentials
        # Create config file with region (required by Nix S3 backend)
        cat > /root/.aws/config << AWSEOF
        [default]
        region = ${AWS_REGION}
        AWSEOF
        chmod 600 /root/.aws/config
        echo "AWS credentials and config configured for Nix daemon"
      - |
        # Configure nix.conf with all settings BEFORE starting daemon
        # The Nix installer can't start daemon properly without systemd,
        # so we manually configure and start it

        # Build the full nix.conf
        TRUSTED_KEYS="cache.nixos.org-1:6NCHdD59X431o0gWypbMrAURkbJ16ZPMQFGspcDShjY="
        [ -f /tmp/.nix_public_key ] && TRUSTED_KEYS="${TRUSTED_KEYS} $(cat /tmp/.nix_public_key)"

        # Read GitHub token
        GITHUB_TOKEN=""
        [ -f /tmp/.github_token ] && GITHUB_TOKEN=$(cat /tmp/.github_token)

        # Write complete nix.conf
        {
          echo "experimental-features = nix-command flakes"
          echo "substituters = https://cache.nixos.org s3://${NIX_CACHE_BUCKET}?region=${AWS_REGION}"
          echo "trusted-public-keys = ${TRUSTED_KEYS}"
          [ -n "${GITHUB_TOKEN}" ] && echo "access-tokens = github.com=${GITHUB_TOKEN}"
        } > /etc/nix/nix.conf

        echo "=== Nix config written ==="
        cat /etc/nix/nix.conf
        echo "=========================="

        # Kill any existing nix-daemon and start fresh with new config
        pkill -9 nix-daemon 2>/dev/null || true
        sleep 1

        # Start nix-daemon manually in background
        /nix/var/nix/profiles/default/bin/nix-daemon &
        sleep 2
        echo "nix-daemon started with PID: $(pgrep nix-daemon || echo 'not found')"
      - |
        # Configure SSH for Nix fetchgit to use with private git repos
        # Copy SSH config and keys to root (nix-daemon runs as root for fetchgit)
        mkdir -p /root/.ssh
        cp -r ~/.ssh/* /root/.ssh/ 2>/dev/null || true
        chmod 700 /root/.ssh
        chmod 600 /root/.ssh/* 2>/dev/null || true
        # Fix crypto-policies conflict by removing the problematic config
        # The system's openssh.config has options not supported by some SSH versions
        rm -f /etc/crypto-policies/back-ends/openssh.config 2>/dev/null || true
        # Verify SSH is available
        echo "SSH configured for Nix fetchgit:"
        which ssh
        ssh -V
      - nix --version

  pre_build:
    commands:
      - echo "|------------------------ pre build --------------------|"
      - |
        APP_REPO_URL=$(cat /tmp/app_repo_url)
        git clone "${APP_REPO_URL}" app-source && cd app-source && git checkout "${GIT_REF}" && cd ..
      - |
        # Clone config repo to read manifest for build_strategy
        CONFIG_REPO_URL=$(cat /tmp/config_repo_url)
        # Convert flake URL back to git clone URL: git+ssh://git@github.com/org/repo?ref=master -> git@github.com:org/repo
        CONFIG_GIT_URL=$(echo "${CONFIG_REPO_URL}" | sed 's|git+ssh://git@|git@|; s|?ref=.*||; s|/|:|1')
        echo "Cloning config repo: ${CONFIG_GIT_URL}"
        git clone "${CONFIG_GIT_URL}" config-source || echo "Warning: Failed to clone config repo"
      - |
        # Resolve BUILD_STRATEGY: manifest component builder > env var > default
        if [ -z "${BUILD_STRATEGY}" ] || [ "${BUILD_STRATEGY}" = "auto" ]; then
          MANIFEST_FILE=""
          if [ -d config-source/deployments/manifests ]; then
            # Find manifest matching APP_NAME (e.g., trade-hunter-staging.yaml, trade-hunter-production.yaml)
            MANIFEST_FILE=$(ls config-source/deployments/manifests/${APP_NAME}*.yaml 2>/dev/null | head -1)
          fi
          if [ -n "${MANIFEST_FILE}" ] && [ -f "${MANIFEST_FILE}" ]; then
            # Extract builder for COMPONENT_NAME, or first component if not specified
            if [ -n "${COMPONENT_NAME}" ]; then
              # Look for specific component's builder
              STRATEGY=$(grep -A10 "^[[:space:]]*${COMPONENT_NAME}:" "${MANIFEST_FILE}" | grep "builder:" | head -1 | sed 's/.*builder:[[:space:]]*//' | tr -d ' \r')
            fi
            if [ -z "${STRATEGY}" ]; then
              # Fallback: get first builder found under components
              STRATEGY=$(grep -E '^[[:space:]]+builder:' "${MANIFEST_FILE}" | head -1 | sed 's/.*builder:[[:space:]]*//' | tr -d ' \r')
            fi
            if [ -n "${STRATEGY}" ]; then
              export BUILD_STRATEGY="${STRATEGY}"
              echo "Read builder from manifest: ${BUILD_STRATEGY}"
            else
              export BUILD_STRATEGY="nix-bundler"
              echo "No builder in manifest, using default: ${BUILD_STRATEGY}"
            fi
          else
            export BUILD_STRATEGY="nix-bundler"
            echo "No manifest found, using default: ${BUILD_STRATEGY}"
          fi
        else
          echo "Using BUILD_STRATEGY from env: ${BUILD_STRATEGY}"
        fi
      - |
        cd app-source
        case "${BUILD_STRATEGY}" in
          nix-bundix)
            echo "=== nix-bundix: Generating gemset.nix ==="
            if [ ! -f Gemfile.lock ]; then echo "ERROR: No Gemfile.lock"; exit 1; fi
            rm -f flake.nix flake.lock
            nix flake init -t "github:glenndavy/rails-builder#rails"
            echo "=== Rails Builder version ==="
            nix run ".#flakeVersion" --accept-flake-config 2>/dev/null || echo "(flakeVersion not available)"
            echo "=============================="
            nix develop ".#with-bundix-bootstrap" --accept-flake-config --impure --command bash -c "
              set -e
              nix run .#generate-dependencies
              [ -f gemset.nix ] && fix-gemset-sha || true
            "
            if [ ! -f gemset.nix ]; then echo "ERROR: gemset.nix generation failed"; exit 1; fi
            git add gemset.nix
            ;;
          nix-bundler)
            echo "=== nix-bundler: No gemset needed ==="
            rm -f flake.nix flake.lock gemset.nix
            ;;
          dockerfile)
            echo "=== dockerfile: Standard Docker build ==="
            if [ ! -f Dockerfile ]; then echo "ERROR: No Dockerfile"; exit 1; fi
            ;;
          *)
            echo "ERROR: Unknown strategy: ${BUILD_STRATEGY}"; exit 1
            ;;
        esac
        cd ..
      - export GIT_SHA=$(cd app-source && git rev-parse HEAD)
      - export SHORT_SHA=$(echo "${GIT_SHA}" | cut -c1-7)
      - 'export TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")'
      - export BUILD_VERSION="${CODEBUILD_BUILD_NUMBER}"
      - export SK="SHA#${GIT_SHA}#B${BUILD_VERSION}"
      - |
        aws dynamodb put-item --table-name "${BUILD_TABLE}" --item "{
          \"pk\": {\"S\": \"APP#${APP_NAME}\"},
          \"sk\": {\"S\": \"${SK}\"},
          \"sha\": {\"S\": \"${GIT_SHA}\"},
          \"build_version\": {\"N\": \"${BUILD_VERSION}\"},
          \"status\": {\"S\": \"building\"},
          \"build_started_at\": {\"S\": \"${TIMESTAMP}\"},
          \"build_id\": {\"S\": \"${CODEBUILD_BUILD_ID}\"},
          \"build_arch\": {\"S\": \"${BUILD_ARCH}\"}
        }"
      - |
        # Verify nix-daemon is running with correct config (configured in install phase)
        echo "=== Verifying Nix Daemon Configuration ==="
        cat /etc/nix/nix.conf
        echo "Daemon PID: $(pgrep nix-daemon || echo 'NOT RUNNING')"
        echo "==========================================="

  build:
    commands:
      - 'export TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")'
      - export APP_SRC_PATH="$(pwd)/app-source"
      - |
        [ "${BUILD_ARCH}" = "arm64" ] && export NIX_SYSTEM="aarch64-linux" || export NIX_SYSTEM="x86_64-linux"
        echo "Building for ${BUILD_ARCH} (${NIX_SYSTEM})"
      - |
        if [ ! -d "${APP_SRC_PATH}" ]; then echo "ERROR: App source not found"; exit 1; fi
      - |
        # Debug: Show cache configuration
        echo "=== Nix Cache Configuration ==="
        echo "System nix.conf (used by daemon):"
        cat /etc/nix/nix.conf 2>/dev/null || echo "(none)"
        echo ""
        echo "NIX_CACHE_BUCKET: ${NIX_CACHE_BUCKET}"
        echo "AWS_REGION: ${AWS_REGION}"
        # Test S3 access
        echo "Testing S3 cache bucket access..."
        aws s3 ls "s3://${NIX_CACHE_BUCKET}/" 2>&1 | head -5 || echo "Warning: Could not list S3 bucket"
        echo "================================"
      - |
        CONFIG_REPO_URL=$(cat /tmp/config_repo_url)

        # Export NIX_CONFIG so nix client has access-tokens for GitHub API
        # The daemon config in /etc/nix/nix.conf doesn't help with flake fetches
        # which are done by the client process
        GITHUB_TOKEN=""
        [ -f /tmp/.github_token ] && GITHUB_TOKEN=$(cat /tmp/.github_token)
        if [ -n "${GITHUB_TOKEN}" ]; then
          export NIX_CONFIG="access-tokens = github.com=${GITHUB_TOKEN}"
          echo "NIX_CONFIG set with GitHub access token"
        fi

        case "${BUILD_STRATEGY}" in
          nix-bundix)
            PACKAGE_NAME="rails-package"
            # Note: Removed --refresh to allow proper cache usage
            # --refresh forces re-checking substituters which can bypass cache
            # --option sandbox false allows network access for private git gems in bundlerEnv
            nix build "${CONFIG_REPO_URL}#packages.${NIX_SYSTEM}.${PACKAGE_NAME}" \
              --override-input rails-app-src "path:${APP_SRC_PATH}" \
              --option sandbox false \
              --accept-flake-config --no-eval-cache --print-build-logs --json > build-result.json
            ;;
          nix-bundler)
            PACKAGE_NAME="rails-package-bundler"
            nix build "${CONFIG_REPO_URL}#packages.${NIX_SYSTEM}.${PACKAGE_NAME}" \
              --override-input rails-app-src "path:${APP_SRC_PATH}" \
              --accept-flake-config --no-eval-cache --print-build-logs --json > build-result.json
            ;;
          dockerfile)
            echo '[]' > build-result.json
            ;;
        esac
      - |
        [ "${BUILD_STRATEGY}" != "dockerfile" ] && export NIX_CLOSURE=$(jq -r '.[0].outputs.out' build-result.json) || export NIX_CLOSURE=""
        echo "Nix closure: ${NIX_CLOSURE}"
      - |
        if [ "${BUILD_STRATEGY}" != "dockerfile" ] && [ -n "${NIX_CLOSURE}" ]; then
          mkdir -p /codebuild/output/tmp && export TMPDIR=/codebuild/output/tmp
          echo "=== Pushing to Nix Cache ==="
          echo "Closure: ${NIX_CLOSURE}"
          echo "Target: s3://${NIX_CACHE_BUCKET}?region=${AWS_REGION}"

          # Count dependencies to be cached
          DEP_COUNT=$(nix path-info -r "${NIX_CLOSURE}" 2>/dev/null | wc -l || echo "unknown")
          echo "Closure contains ${DEP_COUNT} paths (including Ruby gems, dependencies, etc.)"

          if [ -f /tmp/.nix_signing_key ]; then
            echo "Using signing key for cache push"
            nix copy --to "s3://${NIX_CACHE_BUCKET}?region=${AWS_REGION}&secret-key=/tmp/.nix_signing_key" "${NIX_CLOSURE}" -v 2>&1 || echo "Warning: Some paths may have failed to upload"
          else
            echo "Warning: No signing key found, pushing unsigned"
            nix copy --to "s3://${NIX_CACHE_BUCKET}?region=${AWS_REGION}" "${NIX_CLOSURE}" -v 2>&1 || echo "Warning: Some paths may have failed to upload"
          fi

          echo "Cache push complete. Verifying..."
          aws s3 ls "s3://${NIX_CACHE_BUCKET}/" --summarize | tail -5
          echo "=============================="
          aws dynamodb update-item --table-name "${BUILD_TABLE}" \
            --key "{\"pk\": {\"S\": \"APP#${APP_NAME}\"}, \"sk\": {\"S\": \"${SK}\"}}" \
            --update-expression "SET nix_closure = :closure, nix_completed_at = :completed" \
            --expression-attribute-values "{\":closure\": {\"S\": \"${NIX_CLOSURE}\"}, \":completed\": {\"S\": \"${TIMESTAMP}\"}}"
        fi
      - |
        if [ "${BUILD_AMI}" = "true" ]; then
          CONFIG_REPO_URL=$(cat /tmp/config_repo_url)
          nix build "${CONFIG_REPO_URL}#packages.${NIX_SYSTEM}.ec2-image" \
            --override-input rails-app-src "path:${APP_SRC_PATH}" \
            --refresh --no-eval-cache --json > ami-result.json || true
          if [ -f ami-result.json ] && [ -s ami-result.json ]; then
            AMI_PATH=$(jq -r '.[0].outputs.out' ami-result.json)
            AMI_NAME="${APP_NAME}-${BUILD_ARCH}-${SHORT_SHA}-$(date +%Y%m%d%H%M%S)"
            aws s3 cp "${AMI_PATH}/nixos.img" "s3://${NIX_CACHE_BUCKET}/ami-imports/${AMI_NAME}.img"
            IMPORT_TASK=$(aws ec2 import-snapshot \
              --disk-container "Format=RAW,UserBucket={S3Bucket=${NIX_CACHE_BUCKET},S3Key=ami-imports/${AMI_NAME}.img}" \
              --query 'ImportTaskId' --output text)
            aws ec2 wait snapshot-imported --import-task-ids "${IMPORT_TASK}"
            SNAPSHOT_ID=$(aws ec2 describe-import-snapshot-tasks --import-task-ids "${IMPORT_TASK}" \
              --query 'ImportSnapshotTasks[0].SnapshotTaskDetail.SnapshotId' --output text)
            AMI_ID=$(aws ec2 register-image --name "${AMI_NAME}" --architecture "${BUILD_ARCH}" \
              --root-device-name /dev/xvda \
              --block-device-mappings "DeviceName=/dev/xvda,Ebs={SnapshotId=${SNAPSHOT_ID},VolumeType=gp3}" \
              --virtualization-type hvm --ena-support --query 'ImageId' --output text)
            aws dynamodb update-item --table-name "${BUILD_TABLE}" \
              --key "{\"pk\": {\"S\": \"APP#${APP_NAME}\"}, \"sk\": {\"S\": \"${SK}\"}}" \
              --update-expression "SET ami_id = :ami, ami_arch = :arch, ami_completed_at = :completed" \
              --expression-attribute-values "{\":ami\": {\"S\": \"${AMI_ID}\"}, \":arch\": {\"S\": \"${BUILD_ARCH}\"}, \":completed\": {\"S\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}}"
          fi
        fi
      - |
        if [ "${BUILD_DOCKER}" = "true" ]; then
          CONFIG_REPO_URL=$(cat /tmp/config_repo_url)
          DOCKER_BUILD_SUCCESS=false
          case "${BUILD_STRATEGY}" in
            nix-bundix|nix-bundler)
              [ "${BUILD_STRATEGY}" = "nix-bundler" ] && DOCKER_PACKAGE="docker-image-bundler" || DOCKER_PACKAGE="docker-image"
              nix build "${CONFIG_REPO_URL}#packages.${NIX_SYSTEM}.${DOCKER_PACKAGE}" \
                --override-input rails-app-src "path:${APP_SRC_PATH}" \
                --refresh --no-eval-cache --json > docker-result.json || true
              if [ -f docker-result.json ] && [ -s docker-result.json ]; then
                DOCKER_IMAGE=$(jq -r '.[0].outputs.out' docker-result.json)
                [ -n "${DOCKER_IMAGE}" ] && [ "${DOCKER_IMAGE}" != "null" ] && docker load < "${DOCKER_IMAGE}" && DOCKER_BUILD_SUCCESS=true
              fi
              ;;
            dockerfile)
              cd "${APP_SRC_PATH}"
              [ "${BUILD_ARCH}" = "arm64" ] && DOCKER_PLATFORM="linux/arm64" || DOCKER_PLATFORM="linux/amd64"
              docker build --platform "${DOCKER_PLATFORM}" --tag rails-app:latest . && DOCKER_BUILD_SUCCESS=true
              cd -
              ;;
          esac
          if [ "${DOCKER_BUILD_SUCCESS}" = "true" ]; then
            ECR_TAG="sha-${GIT_SHA:0:12}-${BUILD_ARCH}"
            ECR_TAG_VERSIONED="sha-${GIT_SHA:0:12}-${BUILD_ARCH}-b${BUILD_VERSION}"
            aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin ${ECR_REPO}
            docker tag rails-app:latest "${ECR_REPO}:${ECR_TAG}"
            docker tag rails-app:latest "${ECR_REPO}:${ECR_TAG_VERSIONED}"
            docker push "${ECR_REPO}:${ECR_TAG}"
            docker push "${ECR_REPO}:${ECR_TAG_VERSIONED}"
            aws dynamodb update-item --table-name "${BUILD_TABLE}" \
              --key "{\"pk\": {\"S\": \"APP#${APP_NAME}\"}, \"sk\": {\"S\": \"${SK}\"}}" \
              --update-expression "SET ecr_tag = :tag, ecr_tag_versioned = :tag_v, ecr_arch = :arch, docker_completed_at = :completed, build_strategy = :strategy" \
              --expression-attribute-values "{\":tag\": {\"S\": \"${ECR_TAG}\"}, \":tag_v\": {\"S\": \"${ECR_TAG_VERSIONED}\"}, \":arch\": {\"S\": \"${BUILD_ARCH}\"}, \":completed\": {\"S\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}, \":strategy\": {\"S\": \"${BUILD_STRATEGY}\"}}"
          fi
        fi

  post_build:
    commands:
      - |
        TIMESTAMP=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        if [ "${CODEBUILD_BUILD_SUCCEEDING}" = "1" ]; then
          aws dynamodb update-item --table-name "${BUILD_TABLE}" \
            --key "{\"pk\": {\"S\": \"APP#${APP_NAME}\"}, \"sk\": {\"S\": \"${SK}\"}}" \
            --update-expression "SET #status = :status, completed_at = :completed" \
            --expression-attribute-names '{"#status": "status"}' \
            --expression-attribute-values "{\":status\": {\"S\": \"ready\"}, \":completed\": {\"S\": \"${TIMESTAMP}\"}}"
        else
          aws dynamodb update-item --table-name "${BUILD_TABLE}" \
            --key "{\"pk\": {\"S\": \"APP#${APP_NAME}\"}, \"sk\": {\"S\": \"${SK}\"}}" \
            --update-expression "SET #status = :status, failed_at = :failed" \
            --expression-attribute-names '{"#status": "status"}' \
            --expression-attribute-values "{\":status\": {\"S\": \"failed\"}, \":failed\": {\"S\": \"${TIMESTAMP}\"}}"
        fi

cache:
  paths:
    - '/nix/**/*'
    - '/root/.cache/nix/**/*'

artifacts:
  files:
    - build-result.json
    - ami-result.json
    - docker-result.json
  discard-paths: yes


